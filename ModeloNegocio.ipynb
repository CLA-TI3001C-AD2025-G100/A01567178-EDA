{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163237dc",
   "metadata": {},
   "source": [
    "# DE ESTOS NO SIRVE NINGUNO, VAYANSE A TOMAR POR üçë"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d0fec",
   "metadata": {},
   "source": [
    "# EJEMPLO 1 'POBLACION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cargar el archivo con 10 a√±os de datos\n",
    "file_path = \"cuadrantes_df_negocios_mes_anio.xlsx\"\n",
    "df_negocios = pd.read_excel(file_path)\n",
    "\n",
    "# Asumo que la columna de poblaci√≥n es la segunda (√≠ndice 1) y la renombro.\n",
    "df_negocios.rename(columns={df_negocios.columns[1]: 'POBLACION'}, inplace=True)\n",
    "\n",
    "# --- 1. Desapilar (Unpivot) ---\n",
    "# Se mantiene 'CUADRANTE' y 'POBLACION' como identificadores fijos.\n",
    "id_vars = ['CUADRANTE', 'POBLACION']\n",
    "df_long = df_negocios.melt(\n",
    "    id_vars=id_vars,\n",
    "    var_name='MES_ANIO',\n",
    "    value_name='ROBOS_MES_N'\n",
    ")\n",
    "\n",
    "# --- 2. Extraer A√ëO y MES_N ---\n",
    "# Asumo que el formato sigue siendo 'ROBOS A NEGOCIOS MES M YYYY'\n",
    "df_long[['BASURA', 'BASURA2', 'BASURA3', 'BASURA4', 'MES_N', 'ANIO']] = \\\n",
    "    df_long['MES_ANIO'].str.split(' ', expand=True)\n",
    "\n",
    "df_long.drop(columns=['MES_ANIO', 'BASURA', 'BASURA2', 'BASURA3', 'BASURA4'], inplace=True)\n",
    "\n",
    "df_long['MES_N'] = pd.to_numeric(df_long['MES_N'])\n",
    "df_long['ANIO'] = pd.to_numeric(df_long['ANIO'])\n",
    "\n",
    "# --- 3. Ordenar y Crear Indexador √önico ---\n",
    "df_long.sort_values(by=['ANIO', 'MES_N', 'CUADRANTE'], inplace=True)\n",
    "df_long.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 4. Crear las variables N-1 y N-2 agrupadas por cuadrante\n",
    "df_long['ROBOS_MES_N_MENOS_1'] = df_long.groupby('CUADRANTE')['ROBOS_MES_N'].shift(1)\n",
    "df_long['ROBOS_MES_N_MENOS_2'] = df_long.groupby('CUADRANTE')['ROBOS_MES_N'].shift(2)\n",
    "\n",
    "# --- 5. Imputar el Inicio de la Serie (Ene 2015, Feb 2015) ---\n",
    "# Imputamos los valores NaN iniciales con 0\n",
    "df_long.fillna(0, inplace=True)\n",
    "\n",
    "df_final = df_long[['CUADRANTE', 'POBLACION', 'ANIO', 'MES_N', \n",
    "                    'ROBOS_MES_N', 'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']]\n",
    "\n",
    "print(\"### 1. DataFrame Final (Formato de Serie de Tiempo con Poblaci√≥n) ###\")\n",
    "print(f\"Total de filas: {len(df_final)}\") # Deber√≠a ser 9360\n",
    "print(df_final.head(5))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e854dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Separar y Escalar los Datos ---\n",
    "# Variables de Entrada (X): CUADRANTE, POBLACION, ANIO, MES_N, N-1, N-2 (6 variables)\n",
    "X_scale = df_final[['CUADRANTE', 'POBLACION', 'ANIO', 'MES_N', \n",
    "                    'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']].copy()\n",
    "Y_scale = df_final[['ROBOS_MES_N']].copy()\n",
    "\n",
    "# Entrenar los escaladores\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled_values = scaler_X.fit_transform(X_scale)\n",
    "X_scaled = pd.DataFrame(X_scaled_values, columns=X_scale.columns)\n",
    "\n",
    "scaler_Y = MinMaxScaler()\n",
    "Y_scaled_values = scaler_Y.fit_transform(Y_scale)\n",
    "Y_scaled = pd.DataFrame(Y_scaled_values, columns=Y_scale.columns)\n",
    "\n",
    "\n",
    "# --- 2. Agrupar los Datos Escaldados (120 Bloques) ---\n",
    "# Usamos el √≠ndice compuesto (A√ëO y MES_N) para agrupar\n",
    "df_scaled_grouped = X_scaled.copy()\n",
    "df_scaled_grouped['ROBOS_MES_N'] = Y_scaled['ROBOS_MES_N']\n",
    "df_scaled_grouped['GRUPO_MES_ANIO'] = df_final['ANIO'].astype(str) + '-' + df_final['MES_N'].astype(str)\n",
    "\n",
    "\n",
    "# X: Matriz (120 filas, 78 cuadrantes * 6 entradas = 468 columnas)\n",
    "X_cols = ['CUADRANTE', 'POBLACION', 'ANIO', 'MES_N', 'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']\n",
    "X_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')[X_cols].apply(lambda x: x.values.flatten()).tolist()\n",
    "X = np.array(X_data_final)\n",
    "\n",
    "# Y: Matriz (120 filas, 78 columnas)\n",
    "Y_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')['ROBOS_MES_N'].apply(lambda x: x.values).tolist()\n",
    "Y = np.array(Y_data_final)\n",
    "\n",
    "# Dimensiones\n",
    "input_dim = X.shape[1] # 468\n",
    "output_dim = Y.shape[1] # 78\n",
    "\n",
    "# 3. Divisi√≥n para Entrenamiento/Prueba (15 meses para prueba)\n",
    "test_size_months = 15\n",
    "X_train, X_test, Y_train, Y_test = X[:-test_size_months], X[-test_size_months:], Y[:-test_size_months], Y[-test_size_months:]\n",
    "\n",
    "print(f\"Dimensi√≥n de X (Entrenamiento): {X_train.shape}\")\n",
    "print(f\"Dimensi√≥n de X (Prueba): {X_test.shape}\")\n",
    "print(f\"Nueva Dimensi√≥n de Entrada: {input_dim} (78 cuadrantes * 6 variables)\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ba47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Construir y Compilar el Modelo ---\n",
    "# La capa de entrada se ajusta autom√°ticamente a input_dim = 468\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(output_dim, activation='linear') # 78 salidas\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "print(\"### 3. Entrenamiento del Modelo Keras (6 Entradas, 10 A√±os) ###\")\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=300,\n",
    "    batch_size=4,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Entrenamiento finalizado. El modelo ahora incluye la Poblaci√≥n como factor.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 4. Evaluaci√≥n y R^2 ---\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Desescalar la predicci√≥n para R^2 (usando el scaler_Y)\n",
    "Y_test_descaled = scaler_Y.inverse_transform(Y_test.reshape(-1, 1))\n",
    "Y_pred_descaled = scaler_Y.inverse_transform(Y_pred_test.reshape(-1, 1))\n",
    "\n",
    "r2_final = r2_score(Y_test_descaled, Y_pred_descaled)\n",
    "\n",
    "print(f\"### 4. Coeficiente de Determinaci√≥n (R^2) Final: {r2_final:.4f} ###\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a80c68",
   "metadata": {},
   "source": [
    "# EJEMPLO 2 abajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cargar el archivo con 10 a√±os de datos\n",
    "file_path = \"cuadrantes_df_negocios_mes_anio.xlsx\"\n",
    "df_negocios = pd.read_excel(file_path)\n",
    "\n",
    "# --- 1. Desapilar (Unpivot) ---\n",
    "# Transformar la tabla ancha a larga\n",
    "df_long = df_negocios.melt(\n",
    "    id_vars=['CUADRANTE'],\n",
    "    var_name='MES_ANIO',\n",
    "    value_name='ROBOS_MES_N'\n",
    ")\n",
    "\n",
    "# --- 2. Extraer A√ëO y MES_N ---\n",
    "# La columna MES_ANIO tiene el formato 'ROBOS A NEGOCIOS MES M YYYY'\n",
    "df_long[['BASURA', 'BASURA2', 'BASURA3', 'BASURA4', 'MES_N', 'ANIO']] = \\\n",
    "    df_long['MES_ANIO'].str.split(' ', expand=True)\n",
    "\n",
    "df_long.drop(columns=['MES_ANIO', 'BASURA', 'BASURA2', 'BASURA3', 'BASURA4'], inplace=True)\n",
    "\n",
    "df_long['MES_N'] = pd.to_numeric(df_long['MES_N'])\n",
    "df_long['ANIO'] = pd.to_numeric(df_long['ANIO'])\n",
    "\n",
    "# --- 3. Ordenar y Crear Indexador √önico (Para la serie de tiempo) ---\n",
    "df_long.sort_values(by=['ANIO', 'MES_N', 'CUADRANTE'], inplace=True)\n",
    "df_long.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 4. Crear las variables N-1 y N-2 agrupadas por cuadrante\n",
    "# Esto maneja autom√°ticamente las transiciones de mes y a√±o dentro de cada cuadrante\n",
    "df_long['ROBOS_MES_N_MENOS_1'] = df_long.groupby('CUADRANTE')['ROBOS_MES_N'].shift(1)\n",
    "df_long['ROBOS_MES_N_MENOS_2'] = df_long.groupby('CUADRANTE')['ROBOS_MES_N'].shift(2)\n",
    "\n",
    "# --- 5. Imputar el Inicio de la Serie (Ene 2015, Feb 2015) ---\n",
    "# Los primeros 78*2 = 156 robos tienen NaN en N-1 y N-2.\n",
    "# Imputamos con 0, ya que no tenemos datos reales anteriores a Ene 2015.\n",
    "# (Alternativamente, se podr√≠a usar el promedio hist√≥rico si se tuviera).\n",
    "df_long.fillna(0, inplace=True)\n",
    "\n",
    "df_final = df_long[['CUADRANTE', 'ANIO', 'MES_N', 'ROBOS_MES_N', 'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']]\n",
    "\n",
    "print(\"### 1. DataFrame Final (Formato de Serie de Tiempo) ###\")\n",
    "print(f\"Total de filas: {len(df_final)}\") # Deber√≠a ser 9360\n",
    "print(df_final.head(5))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a65326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar a excel\n",
    "# df_final.to_excel('df_finalnegocio_serie_tiempo.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46741a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Separar y Escalar los Datos ---\n",
    "# Variables de Entrada (X): CUADRANTE, ANIO, MES_N, N-1, N-2\n",
    "# Variable de Salida (Y): ROBOS_MES_N\n",
    "X_scale = df_final[['CUADRANTE', 'ANIO', 'MES_N', 'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']].copy()\n",
    "Y_scale = df_final[['ROBOS_MES_N']].copy()\n",
    "\n",
    "# Entrenar el escalador solo con X (y Y)\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled_values = scaler_X.fit_transform(X_scale)\n",
    "X_scaled = pd.DataFrame(X_scaled_values, columns=X_scale.columns)\n",
    "\n",
    "scaler_Y = MinMaxScaler()\n",
    "Y_scaled_values = scaler_Y.fit_transform(Y_scale)\n",
    "Y_scaled = pd.DataFrame(Y_scaled_values, columns=Y_scale.columns)\n",
    "\n",
    "\n",
    "# --- 2. Agrupar los Datos Escaldados (Creando los 120 Bloques) ---\n",
    "# Usamos un √≠ndice compuesto (A√ëO y MES_N) para agrupar\n",
    "df_scaled_grouped = X_scaled.copy()\n",
    "df_scaled_grouped['ROBOS_MES_N'] = Y_scaled['ROBOS_MES_N']\n",
    "df_scaled_grouped['GRUPO_MES_ANIO'] = df_final['ANIO'].astype(str) + '-' + df_final['MES_N'].astype(str)\n",
    "\n",
    "\n",
    "# X: Matriz (120 filas, 78*5=390 columnas)\n",
    "X_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')[['CUADRANTE', 'ANIO', 'MES_N', 'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']].apply(lambda x: x.values.flatten()).tolist()\n",
    "X = np.array(X_data_final)\n",
    "\n",
    "# Y: Matriz (120 filas, 78 columnas)\n",
    "Y_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')['ROBOS_MES_N'].apply(lambda x: x.values).tolist()\n",
    "Y = np.array(Y_data_final)\n",
    "\n",
    "# Dimensiones\n",
    "input_dim = X.shape[1] # 78 cuadrantes * 5 entradas = 390\n",
    "output_dim = Y.shape[1] # 78\n",
    "\n",
    "# 3. Divisi√≥n para Entrenamiento/Prueba (Usamos los √∫ltimos 15 meses para prueba)\n",
    "test_size_months = 15 # 15 meses para prueba\n",
    "X_train, X_test, Y_train, Y_test = X[:-test_size_months], X[-test_size_months:], Y[:-test_size_months], Y[-test_size_months:]\n",
    "\n",
    "print(f\"Dimensi√≥n de X (Entrenamiento): {X_train.shape}\") # Deber√≠a ser ~105 filas\n",
    "print(f\"Dimensi√≥n de X (Prueba): {X_test.shape}\") # Deber√≠a ser 15 filas\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab15c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASUMIMOS QUE X_train, Y_train, input_dim, output_dim, y los scalers EST√ÅN DEFINIDOS\n",
    "\n",
    "from tensorflow.keras.layers import LSTM # <-- Nueva capa clave\n",
    "\n",
    "# Adaptar las matrices X para la capa LSTM (A√±adir un timestep = 1)\n",
    "# Forma original: (Muestras, Caracter√≠sticas) -> (105, 390)\n",
    "# Nueva forma requerida por LSTM: (Muestras, Timesteps, Caracter√≠sticas)\n",
    "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "print(f\"Nueva Dimensi√≥n de X_train para LSTM: {X_train_lstm.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 1. Construir el Modelo LSTM ---\n",
    "model_lstm = Sequential([\n",
    "    # Capa LSTM: Ideal para la secuencia temporal. return_sequences=False porque\n",
    "    # solo tenemos 1 timestep.\n",
    "    LSTM(128, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
    "    \n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Capa Densa (para integrar los resultados de LSTM)\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Capa de salida (78 salidas)\n",
    "    Dense(output_dim, activation='linear')\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
    "\n",
    "early_stop_lstm = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
    "\n",
    "print(\"### Entrenamiento del Modelo LSTM (Con 10 A√±os de Datos) ###\")\n",
    "history_lstm = model_lstm.fit(\n",
    "    X_train_lstm, Y_train,\n",
    "    epochs=500, # Aumentamos las √©pocas\n",
    "    batch_size=4,\n",
    "    validation_data=(X_test_lstm, Y_test),\n",
    "    callbacks=[early_stop_lstm],\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Entrenamiento LSTM finalizado.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 2. Evaluaci√≥n y R^2 ---\n",
    "Y_pred_test_lstm = model_lstm.predict(X_test_lstm)\n",
    "\n",
    "# Desescalar la predicci√≥n para R^2 (usando el scaler_Y)\n",
    "Y_test_descaled = scaler_Y.inverse_transform(Y_test.reshape(-1, 1))\n",
    "Y_pred_descaled_lstm = scaler_Y.inverse_transform(Y_pred_test_lstm.reshape(-1, 1))\n",
    "\n",
    "r2_lstm_final = r2_score(Y_test_descaled, Y_pred_descaled_lstm)\n",
    "\n",
    "print(f\"### Nuevo Coeficiente de Determinaci√≥n (R^2) con LSTM: {r2_lstm_final:.4f} ###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Construir y Compilar el Modelo ---\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(output_dim, activation='linear') # 78 salidas\n",
    "])\n",
    "\n",
    "# Usamos un Learning Rate conservador para evitar divergencia con m√°s datos\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "print(\"### 3. Entrenamiento del Modelo Keras (10 A√±os de Datos) ###\")\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=300, # Aumentamos las √©pocas\n",
    "    batch_size=4,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Entrenamiento finalizado. El modelo es mucho m√°s robusto ahora.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 4. Evaluaci√≥n y R^2 ---\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Desescalar la predicci√≥n para R^2 (usando el scaler_Y)\n",
    "Y_test_descaled = scaler_Y.inverse_transform(Y_test.reshape(-1, 1))\n",
    "Y_pred_descaled = scaler_Y.inverse_transform(Y_pred_test.reshape(-1, 1))\n",
    "\n",
    "r2_final = r2_score(Y_test_descaled, Y_pred_descaled)\n",
    "\n",
    "print(f\"### 4. Coeficiente de Determinaci√≥n (R^2) Final: {r2_final:.4f} ###\")\n",
    "\n",
    "if r2_final > 0.6:\n",
    "    print(\"‚úÖ ¬°El modelo ha mejorado significativamente su precisi√≥n con m√°s datos!\")\n",
    "elif r2_final > 0.0:\n",
    "    print(\"‚ö†Ô∏è Precisi√≥n positiva. Se puede mejorar ajustando hiperpar√°metros.\")\n",
    "else:\n",
    "    print(\"‚ùå A√∫n hay problemas. Revisar el escalado o la arquitectura.\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505adb5",
   "metadata": {},
   "source": [
    "# Ejemplo 3 con POBLACION, sin MES_N y ANIO, y CUADRANTE en variable DUMMIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cargar el archivo con 10 a√±os de datos\n",
    "file_path = \"cuadrantes_df_negocios_mes_anio.xlsx\"\n",
    "df_wide = pd.read_excel(file_path)\n",
    "\n",
    "# Asumo que la columna de poblaci√≥n es la segunda y la renombro.\n",
    "df_wide.rename(columns={df_wide.columns[1]: 'POBLACION'}, inplace=True)\n",
    "\n",
    "# --- 1. Desapilar (Unpivot) ---\n",
    "id_vars = ['CUADRANTE', 'POBLACION']\n",
    "df_long = df_wide.melt(\n",
    "    id_vars=id_vars,\n",
    "    var_name='MES_ANIO',\n",
    "    value_name='ROBOS_MES_N'\n",
    ")\n",
    "\n",
    "# --- 2. Extraer A√ëO y MES_N ---\n",
    "df_long[['BASURA', 'BASURA2', 'BASURA3', 'BASURA4', 'MES_N', 'ANIO']] = \\\n",
    "    df_long['MES_ANIO'].str.split(' ', expand=True)\n",
    "\n",
    "df_long.drop(columns=['MES_ANIO', 'BASURA', 'BASURA2', 'BASURA3', 'BASURA4'], inplace=True)\n",
    "\n",
    "df_long['MES_N'] = pd.to_numeric(df_long['MES_N'])\n",
    "df_long['ANIO'] = pd.to_numeric(df_long['ANIO'])\n",
    "\n",
    "# --- 3. Ordenar y Crear Indexador √önico ---\n",
    "df_long.sort_values(by=['ANIO', 'MES_N', 'CUADRANTE'], inplace=True)\n",
    "df_long.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 4. Crear las variables N-1 y N-2\n",
    "#df_long['ROBOS_MES_N_MENOS_1'] = df_long.groupby('CUADRANTE')['ROBOS_MES_N'].shift(1)\n",
    "#df_long['ROBOS_MES_N_MENOS_2'] = df_long.groupby('CUADRANTE')['ROBOS_MES_N'].shift(2)\n",
    "\n",
    "# --- 5. Imputar el Inicio de la Serie ---\n",
    "#df_long.fillna(0, inplace=True)\n",
    "\n",
    "#df_final = df_long[['CUADRANTE', 'POBLACION', 'ANIO', 'MES_N', \n",
    "#                    'ROBOS_MES_N', 'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']]\n",
    "\n",
    "#print(\"### 1. DataFrame Final listo (9360 Filas) ###\")\n",
    "#print(df_final.head(5))\n",
    "#print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed07401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumimos que df_long del Paso 1 est√° cargado y ordenado por ANIO, MES_N, CUADRANTE.\n",
    "# Si no lo tienes, usa el c√≥digo completo del Paso 1 de la respuesta anterior para obtener df_long.\n",
    "\n",
    "# 4. Crear las variables N-1 hasta N-6 agrupadas por cuadrante\n",
    "for i in range(1, 7):\n",
    "    df_long[f'ROBOS_MES_N_MENOS_{i}'] = df_long.groupby('CUADRANTE')['ROBOS_MES_N'].shift(i)\n",
    "\n",
    "# --- 5. Imputar el Inicio de la Serie ---\n",
    "# Ahora hay m√°s NaNs al inicio (los primeros 78*6 = 468 valores).\n",
    "df_long.fillna(0, inplace=True)\n",
    "\n",
    "df_final = df_long[[\n",
    "    'CUADRANTE', 'POBLACION', 'ANIO', 'MES_N', 'ROBOS_MES_N', \n",
    "    'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2', 'ROBOS_MES_N_MENOS_3',\n",
    "    'ROBOS_MES_N_MENOS_4', 'ROBOS_MES_N_MENOS_5', 'ROBOS_MES_N_MENOS_6'\n",
    "]].copy()\n",
    "\n",
    "print(\"### 1. DataFrame Final con 6 Meses de Historia ###\")\n",
    "print(f\"Total de filas: {len(df_final)}\")\n",
    "print(df_final.head(7))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Separar y Aplicar One-Hot Encoding (OHE) a CUADRANTE ---\n",
    "df_final_ohe = df_final.copy()\n",
    "df_ohe = pd.get_dummies(df_final_ohe['CUADRANTE'], prefix='C')\n",
    "df_final_ohe = pd.concat([df_final_ohe.drop('CUADRANTE', axis=1), df_ohe], axis=1)\n",
    "\n",
    "# --- 2. Separar y Escalar los Datos (9 Variables) ---\n",
    "X_cols_ohe = [col for col in df_final_ohe.columns if col.startswith('C_')] # 78 columnas OHE\n",
    "\n",
    "# Nuevas variables de entrada: 78 (OHE) + POBLACION + 6 Hist√≥ricas\n",
    "X_cols = X_cols_ohe + ['POBLACION']\n",
    "X_cols += [f'ROBOS_MES_N_MENOS_{i}' for i in range(1, 7)] # 6 columnas de historia\n",
    "\n",
    "X_scale = df_final_ohe[X_cols].copy()\n",
    "Y_scale = df_final_ohe[['ROBOS_MES_N']].copy()\n",
    "\n",
    "# Entrenar los escaladores (scaler_X y scaler_Y)\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled_values = scaler_X.fit_transform(X_scale)\n",
    "X_scaled = pd.DataFrame(X_scaled_values, columns=X_scale.columns)\n",
    "scaler_Y = MinMaxScaler()\n",
    "Y_scaled_values = scaler_Y.fit_transform(Y_scale)\n",
    "Y_scaled = pd.DataFrame(Y_scaled_values, columns=Y_scale.columns)\n",
    "\n",
    "# --- 3. Agrupar los Datos Escaldados (120 Bloques) ---\n",
    "df_scaled_grouped = X_scaled.copy()\n",
    "df_scaled_grouped['ROBOS_MES_N'] = Y_scaled['ROBOS_MES_N']\n",
    "df_scaled_grouped['GRUPO_MES_ANIO'] = df_final_ohe['ANIO'].astype(str) + '-' + df_final_ohe['MES_N'].astype(str)\n",
    "\n",
    "# X: Matriz (120 filas, 78 cuadrantes * 85 entradas = 6630 columnas)\n",
    "X_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')[X_cols].apply(lambda x: x.values.flatten()).tolist()\n",
    "X = np.array(X_data_final)\n",
    "\n",
    "# Y: Matriz (120 filas, 78 columnas)\n",
    "Y_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')['ROBOS_MES_N'].apply(lambda x: x.values).tolist()\n",
    "Y = np.array(Y_data_final)\n",
    "\n",
    "# Dimensiones\n",
    "input_dim = X.shape[1] # 6630\n",
    "output_dim = Y.shape[1] # 78\n",
    "\n",
    "# Divisi√≥n para Entrenamiento/Prueba (15 meses para prueba)\n",
    "test_size_months = 15\n",
    "X_train, X_test, Y_train, Y_test = X[:-test_size_months], X[-test_size_months:], Y[:-test_size_months], Y[-test_size_months:]\n",
    "\n",
    "print(f\"Nueva Dimensi√≥n de Entrada: {input_dim} (78 cuadrantes * 85 variables)\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930fa203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Construir y Compilar el Modelo ---\n",
    "model = Sequential([\n",
    "    Dense(1024, activation='relu', input_shape=(input_dim,)), \n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu'), \n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(output_dim, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "print(\"### 3. Entrenamiento con 6 Meses de Historia ###\")\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=500, \n",
    "    batch_size=2, \n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Entrenamiento finalizado. El modelo ahora tiene un contexto de 6 meses.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 4. Evaluaci√≥n y R^2 ---\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Desescalar la predicci√≥n para R^2 (usando el scaler_Y)\n",
    "Y_test_descaled = scaler_Y.inverse_transform(Y_test.reshape(-1, 1))\n",
    "Y_pred_descaled = scaler_Y.inverse_transform(Y_pred_test.reshape(-1, 1))\n",
    "\n",
    "r2_final = r2_score(Y_test_descaled, Y_pred_descaled)\n",
    "\n",
    "print(f\"### 4. Coeficiente de Determinaci√≥n (R^2) Final (¬°Busca el 70%+!): {r2_final:.4f} ###\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Separar y Aplicar One-Hot Encoding (OHE) a CUADRANTE ---\n",
    "df_final_ohe = df_final.copy()\n",
    "\n",
    "# Aplicar OHE a la columna CUADRANTE\n",
    "df_ohe = pd.get_dummies(df_final_ohe['CUADRANTE'], prefix='C')\n",
    "df_final_ohe = pd.concat([df_final_ohe.drop('CUADRANTE', axis=1), df_ohe], axis=1)\n",
    "\n",
    "\n",
    "# --- 2. Separar y Escalar los Datos (Nuevas Entradas) ---\n",
    "# X_cols: 78 columnas OHE + POBLACION + N-1 + N-2 (81 variables)\n",
    "X_cols = [col for col in df_final_ohe.columns if col.startswith('C_')] # Las 78 columnas OHE\n",
    "X_cols += ['POBLACION', 'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']\n",
    "\n",
    "X_scale = df_final_ohe[X_cols].copy()\n",
    "Y_scale = df_final_ohe[['ROBOS_MES_N']].copy()\n",
    "\n",
    "# Entrenar los escaladores\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled_values = scaler_X.fit_transform(X_scale)\n",
    "X_scaled = pd.DataFrame(X_scaled_values, columns=X_scale.columns)\n",
    "\n",
    "scaler_Y = MinMaxScaler()\n",
    "Y_scaled_values = scaler_Y.fit_transform(Y_scale)\n",
    "Y_scaled = pd.DataFrame(Y_scaled_values, columns=Y_scale.columns)\n",
    "\n",
    "\n",
    "# --- 3. Agrupar los Datos Escaldados (120 Bloques) ---\n",
    "df_scaled_grouped = X_scaled.copy()\n",
    "df_scaled_grouped['ROBOS_MES_N'] = Y_scaled['ROBOS_MES_N']\n",
    "df_scaled_grouped['GRUPO_MES_ANIO'] = df_final_ohe['ANIO'].astype(str) + '-' + df_final_ohe['MES_N'].astype(str)\n",
    "\n",
    "# X: Matriz (120 filas, 78 cuadrantes * 81 entradas = 6318 columnas)\n",
    "X_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')[X_cols].apply(lambda x: x.values.flatten()).tolist()\n",
    "X = np.array(X_data_final)\n",
    "\n",
    "# Y: Matriz (120 filas, 78 columnas)\n",
    "Y_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')['ROBOS_MES_N'].apply(lambda x: x.values).tolist()\n",
    "Y = np.array(Y_data_final)\n",
    "\n",
    "# Dimensiones\n",
    "input_dim = X.shape[1] # 6318\n",
    "output_dim = Y.shape[1] # 78\n",
    "\n",
    "# Divisi√≥n para Entrenamiento/Prueba (15 meses para prueba)\n",
    "test_size_months = 15\n",
    "X_train, X_test, Y_train, Y_test = X[:-test_size_months], X[-test_size_months:], Y[:-test_size_months], Y[-test_size_months:]\n",
    "\n",
    "print(f\"Dimensi√≥n de X (Entrenamiento): {X_train.shape}\")\n",
    "print(f\"Nueva Dimensi√≥n de Entrada: {input_dim} (78 cuadrantes * 81 variables)\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Construir y Compilar el Modelo (Capacidad Aumentada) ---\n",
    "model = Sequential([\n",
    "    Dense(1024, activation='relu', input_shape=(input_dim,)), # Aumentada\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu'), # Aumentada\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(output_dim, activation='linear') # 78 salidas\n",
    "])\n",
    "\n",
    "# Mantenemos el LR muy bajo para ser conservadores\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "print(\"### 3. Entrenamiento con One-Hot Encoding (OHE) y Mayor Capacidad ###\")\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=500, \n",
    "    batch_size=2, \n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Entrenamiento finalizado. Este modelo aprende la firma de cada cuadrante.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 4. Evaluaci√≥n y R^2 ---\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Desescalar la predicci√≥n para R^2 (usando el scaler_Y)\n",
    "Y_test_descaled = scaler_Y.inverse_transform(Y_test.reshape(-1, 1))\n",
    "Y_pred_descaled = scaler_Y.inverse_transform(Y_pred_test.reshape(-1, 1))\n",
    "\n",
    "r2_final = r2_score(Y_test_descaled, Y_pred_descaled)\n",
    "\n",
    "print(f\"### 4. Coeficiente de Determinaci√≥n (R^2) Final (Objetivo 70%+): {r2_final:.4f} ###\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Separar y Escalar los Datos ---\n",
    "# X AHORA SOLO CONTIENE 4 VARIABLES: CUADRANTE, POBLACION, N-1, N-2\n",
    "X_scale = df_final[['CUADRANTE', 'POBLACION', 'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']].copy()\n",
    "Y_scale = df_final[['ROBOS_MES_N']].copy()\n",
    "\n",
    "# Entrenar los escaladores\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled_values = scaler_X.fit_transform(X_scale)\n",
    "X_scaled = pd.DataFrame(X_scaled_values, columns=X_scale.columns)\n",
    "\n",
    "scaler_Y = MinMaxScaler()\n",
    "Y_scaled_values = scaler_Y.fit_transform(Y_scale)\n",
    "Y_scaled = pd.DataFrame(Y_scaled_values, columns=Y_scale.columns)\n",
    "\n",
    "\n",
    "# --- 2. Agrupar los Datos Escaldados (120 Bloques) ---\n",
    "df_scaled_grouped = X_scaled.copy()\n",
    "df_scaled_grouped['ROBOS_MES_N'] = Y_scaled['ROBOS_MES_N']\n",
    "# Usamos el √≠ndice de tiempo (A√ëO y MES_N) solo para agrupar, pero NO como input de X\n",
    "df_scaled_grouped['GRUPO_MES_ANIO'] = df_final['ANIO'].astype(str) + '-' + df_final['MES_N'].astype(str)\n",
    "\n",
    "\n",
    "# X: Matriz (120 filas, 78 cuadrantes * 4 entradas = 312 columnas)\n",
    "X_cols = ['CUADRANTE', 'POBLACION', 'ROBOS_MES_N_MENOS_1', 'ROBOS_MES_N_MENOS_2']\n",
    "X_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')[X_cols].apply(lambda x: x.values.flatten()).tolist()\n",
    "X = np.array(X_data_final)\n",
    "\n",
    "# Y: Matriz (120 filas, 78 columnas)\n",
    "Y_data_final = df_scaled_grouped.groupby('GRUPO_MES_ANIO')['ROBOS_MES_N'].apply(lambda x: x.values).tolist()\n",
    "Y = np.array(Y_data_final)\n",
    "\n",
    "# Dimensiones\n",
    "input_dim = X.shape[1] # 312\n",
    "output_dim = Y.shape[1] # 78\n",
    "\n",
    "# 3. Divisi√≥n para Entrenamiento/Prueba (15 meses para prueba)\n",
    "test_size_months = 15\n",
    "X_train, X_test, Y_train, Y_test = X[:-test_size_months], X[-test_size_months:], Y[:-test_size_months], Y[-test_size_months:]\n",
    "\n",
    "print(f\"Dimensi√≥n de X (Entrenamiento): {X_train.shape}\")\n",
    "print(f\"Dimensi√≥n de X (Prueba): {X_test.shape}\")\n",
    "print(f\"Nueva Dimensi√≥n de Entrada: {input_dim} (78 cuadrantes * 4 variables)\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e85da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Construir y Compilar el Modelo ---\n",
    "# La capa de entrada se ajusta autom√°ticamente a input_dim = 312\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(output_dim, activation='linear') # 78 salidas\n",
    "])\n",
    "\n",
    "# Usamos Learning Rate muy bajo y batch_size reducido para mejor convergencia\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "\n",
    "# Usamos alta paciencia\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "print(\"### 3. Entrenamiento con 4 Entradas (Mejorado) ###\")\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=500, \n",
    "    batch_size=2, \n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Entrenamiento finalizado. El modelo ahora enfoca su aprendizaje en las variables clave.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 4. Evaluaci√≥n y R^2 ---\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Desescalar la predicci√≥n para R^2 (usando el scaler_Y)\n",
    "Y_test_descaled = scaler_Y.inverse_transform(Y_test.reshape(-1, 1))\n",
    "Y_pred_descaled = scaler_Y.inverse_transform(Y_pred_test.reshape(-1, 1))\n",
    "\n",
    "r2_final = r2_score(Y_test_descaled, Y_pred_descaled)\n",
    "\n",
    "print(f\"### 4. Coeficiente de Determinaci√≥n (R^2) Final: {r2_final:.4f} ###\")\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
